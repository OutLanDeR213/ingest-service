import csv
import sys
import json
import logging
from dateutil import parser
from typing import Dict, Any, List
from pydantic import BaseModel, ValidationError, field_validator
from .database import SessionLocal, engine
from . import models

# Ð¾Ð±Ñ‹Ñ‡Ð½Ñ‹Ð¹ Ð·Ð°Ð¿ÑƒÑÐº (sample)
#python -m event_service.import_events

# Ñ‚ÐµÑÑ‚Ð¾Ð²Ð°Ñ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐ°
#python -m event_service.import_events data/events_100k.csv

# === Ð›Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ ===
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
)
logger = logging.getLogger("import_events")

error_log = open("import_errors.log", "w", encoding="utf-8")

# === Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹, ÐµÑÐ»Ð¸ Ð¸Ñ… Ð½ÐµÑ‚ ===
models.Base.metadata.create_all(bind=engine)


# === Pydantic-Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð´Ð»Ñ Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ð¸ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ð¹ ===
class EventSchema(BaseModel):
    event_id: str
    occurred_at: str
    user_id: str
    event_type: str
    properties_json: Any = {}

    @field_validator("occurred_at")
    def validate_date(cls, v):
        try:
            return parser.parse(v)
        except Exception:
            raise ValueError(f"ÐÐµÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ñ‹Ð¹ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ Ð´Ð°Ñ‚Ñ‹: {v}")

    @field_validator("properties_json", mode="before")
    def parse_json(cls, v):
        """ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ Ð¿Ð°Ñ€ÑÐ¸Ð¼ JSON, Ð´Ð°Ð¶Ðµ ÐµÑÐ»Ð¸ Ð¾Ð½ ÑÑ‚Ñ€Ð¾ÐºÐ°"""
        if isinstance(v, str):
            try:
                return json.loads(v)
            except Exception:
                return {}
        return v or {}


def import_events(path: str, batch_size: int = 1000):
    db = SessionLocal()
    imported, skipped, failed = 0, 0, 0
    batch: List[models.Event] = []

    try:
        with open(path, newline='', encoding='utf-8') as csvfile:
            reader = csv.DictReader(csvfile)
            required_cols = {"event_id", "occurred_at", "user_id", "event_type"}
            if not required_cols.issubset(reader.fieldnames):
                logger.error(f"CSV Ð´Ð¾Ð»Ð¶ÐµÐ½ ÑÐ¾Ð´ÐµÑ€Ð¶Ð°Ñ‚ÑŒ ÐºÐ¾Ð»Ð¾Ð½ÐºÐ¸: {required_cols}")
                sys.exit(1)

            for i, row in enumerate(reader, start=1):
                try:
                    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð´ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ‚Ð¾Ð²
                    if db.query(models.Event).filter_by(event_id=row["event_id"]).first():
                        skipped += 1
                        continue

                    # Ð’Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ñ Ñ‡ÐµÑ€ÐµÐ· Pydantic
                    evt = EventSchema(**row)

                    # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ ORM Ð¾Ð±ÑŠÐµÐºÑ‚
                    event = models.Event(
                        event_id=evt.event_id,
                        occurred_at=evt.occurred_at,
                        user_id=evt.user_id,
                        event_type=evt.event_type,
                        properties=evt.properties_json,  # âœ… Ñ‚ÐµÐ¿ÐµÑ€ÑŒ JSON ÑƒÐ¶Ðµ Ñ€Ð°ÑÐ¿Ð°Ñ€ÑˆÐµÐ½
                    )

                    batch.append(event)
                    imported += 1

                    # Ð•ÑÐ»Ð¸ Ð´Ð¾ÑÑ‚Ð¸Ð³Ð»Ð¸ Ñ€Ð°Ð·Ð¼ÐµÑ€Ð° Ð±Ð°Ñ‚Ñ‡Ð° â€” ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼
                    if len(batch) >= batch_size:
                        db.bulk_save_objects(batch)
                        db.commit()
                        batch.clear()

                except ValidationError as ve:
                    failed += 1
                    msg = f"[{i}] ÐžÑˆÐ¸Ð±ÐºÐ° Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ð¸: {ve}\nÐ¡Ñ‚Ñ€Ð¾ÐºÐ°: {row}\n"
                    error_log.write(msg + "\n")
                except Exception as e:
                    failed += 1
                    msg = f"[{i}] ÐžÐ±Ñ‰Ð°Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ°: {e}\nÐ¡Ñ‚Ñ€Ð¾ÐºÐ°: {row}\n"
                    error_log.write(msg + "\n")

            # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð¾ÑÑ‚Ð°Ð²ÑˆÐ¸ÐµÑÑ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ñ
            if batch:
                db.bulk_save_objects(batch)
                db.commit()

        logger.info("âœ… Ð˜Ð¼Ð¿Ð¾Ñ€Ñ‚ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾")
        logger.info(f"   âž• Ð˜Ð¼Ð¿Ð¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¾: {imported}")
        logger.info(f"   âš™ï¸ ÐŸÑ€Ð¾Ð¿ÑƒÑ‰ÐµÐ½Ð¾ (Ð´ÑƒÐ±Ð»Ð¸): {skipped}")
        logger.info(f"   âŒ ÐžÑˆÐ¸Ð±Ð¾Ðº: {failed}")

    except FileNotFoundError:
        logger.error(f"Ð¤Ð°Ð¹Ð» Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½: {path}")
        sys.exit(1)
    except Exception as e:
        logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¸Ð¼Ð¿Ð¾Ñ€Ñ‚Ðµ: {e}")
        sys.exit(1)
    finally:
        db.close()
        error_log.close()


import os

if __name__ == "__main__":
    default_path = os.getenv("EVENTS_CSV_PATH", "data/events_sample.csv")
    path = sys.argv[1] if len(sys.argv) > 1 else default_path
    logger.info(f"ðŸ“¦ Ð˜Ð¼Ð¿Ð¾Ñ€Ñ‚ Ð¸Ð· Ñ„Ð°Ð¹Ð»Ð°: {path}")
    import_events(path)
